import os
import json
from dotenv import load_dotenv
import operator
from typing import TypedDict, Annotated, List, Optional
from pydantic import BaseModel, Field
from langchain_core.messages import AnyMessage, HumanMessage, AIMessage, SystemMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import JsonOutputParser
from langgraph.graph import StateGraph, START, END

class ClarifyingQuestionsResult(BaseModel):
    clarifying_questions: List[str] = Field(description="ì¶”ê°€ ì§ˆë¬¸ ëª©ë¡")
    
class UserResponseResult(BaseModel):
    ask_question: str = Field(description="ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ë©”ì‹œì§€ í…ìŠ¤íŠ¸")
    result: str = Field(description="ì§ˆë¬¸ì— ëŒ€í•œ ì‚¬ìš©ì ì‘ë‹µ ê²°ê³¼ë¥¼ ì •ë¦¬í•œ í…ìŠ¤íŠ¸")
    is_complete: bool = Field(description="ì‚¬ìš©ìì˜ ì‘ë‹µì´ ì¶©ë¶„í•œì§€ íŒë‹¨í•˜ë¼. ì¶©ë¶„í•˜ë©´ true, ì•„ë‹ˆë©´ false")

class AgentState(TypedDict):
    request: str
    clarifying_questions: List[str]
    ask_question : str
    result: str
    messages: Annotated[list, operator.add]
    is_complete: bool

def generate_clarifying_questions(state: AgentState):
    """ì‚¬ìš©ìì˜ ìš”ì²­ì‚¬í•­ì— ëŒ€í•´ ì¶”ê°€ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë…¸ë“œ"""
    print("--- ğŸ“ ì¶”ê°€ ì§ˆë¬¸ ìƒì„± ì¤‘... ---")
    parser = JsonOutputParser(pydantic_object=ClarifyingQuestionsResult)
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-pro")
    system_prompt = """
    ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ìš”êµ¬ì‚¬í•­ ë¶„ì„ê°€ì´ì ì†Œí”„íŠ¸ì›¨ì–´ ì•„í‚¤í…íŠ¸ë‹¤. ëª…ì„¸ì„œ ì‘ì„±ì— ì•ì„œ ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•  í•µì‹¬ ì§ˆë¬¸ 2~4ê°€ì§€ë¥¼ ìƒì„±í•˜ì„¸ìš”. 
    ì§ˆë¬¸ì€ í”„ë¡œì íŠ¸ì˜ ë²”ìœ„, í•µì‹¬ ê¸°ëŠ¥, ì œì•½ ì¡°ê±´ì„ ëª…í™•íˆ í•˜ëŠ” ë° ì´ˆì ì„ ë§ì¶°ì•¼ í•©ë‹ˆë‹¤
    
    [ì¶”ê°€ ì§ˆë¬¸ ìƒì„± ê·œì¹™]
    - ì‚¬ìš©ìì˜ ìš”ì²­ì‚¬í•­ì— ëŒ€í•´ ì¶”ê°€ ì§ˆë¬¸ì„ ìƒì„±í•˜ë¼.
    - ì¶”ê°€ ì§ˆë¬¸ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì‚¬í•­ì— ëŒ€í•´ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œì§€ íŒë‹¨í•˜ëŠ” ì§ˆë¬¸ì´ë‹¤.
    - ì¶”ê°€ ì§ˆë¬¸ì€ ìµœëŒ€ 4ê°€ì§€ê¹Œì§€ ìƒì„±í•˜ë¼.
    - ì¶”ê°€ ì§ˆë¬¸ì€ ëª¨í˜¸í•˜ì§€ ì•Šê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ë¼.

    [ì‚°ì¶œë¬¼ ê¸°ì¤€]
    - ëª¨ë“  ì¶œë ¥ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤.
    - ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ ì œê³µëœ JSON ìŠ¤í‚¤ë§ˆ ì§€ì¹¨ì„ ì—„ê²¹íˆ ë”°ë¥¸ë‹¤. í•„ë“œ ì´ë¦„ì„ ì„ì˜ë¡œ ë³€ê²½í•˜ì§€ ì•ŠëŠ”ë‹¤.
      - clarifying_questions: ì¶”ê°€ ì§ˆë¬¸ ëª©ë¡.

    {format_instructions}
    """

    prompt = ChatPromptTemplate([
        ("system", system_prompt),
        ("human", "ì‚¬ìš©ì ì‘ë‹µ: {request}")
    ])
    chain = prompt | llm | parser
    result = chain.invoke({
        "format_instructions": parser.get_format_instructions(),
        "request": state["request"]
    })
    print("--------------------------------")
    print(result["clarifying_questions"])
    print("--------------------------------")

    return {
        "clarifying_questions": result["clarifying_questions"]
    }

def generate_user_request(state: AgentState):
    """ì‚¬ìš©ìì˜ ìš”ì²­ì„ ìƒì„±í•˜ëŠ” ë…¸ë“œ"""
    print("--- ğŸ“ ì‚¬ìš©ìì˜ ìš”ì²­ì„ ìƒì„±í•˜ëŠ” ì¤‘... ---")

    parser = JsonOutputParser(pydantic_object=UserResponseResult)
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash")
    system_prompt = """
    ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ë¥¼ í˜„ì‹¤ë¡œ ë§Œë“¤ì–´ì£¼ëŠ” ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ AI í”„ë¡œì íŠ¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
    ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ë”±ë”±í•œ ì§ˆë¬¸ ëª©ë¡ì„ ë”°ëœ»í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¡œ ë°”ê¾¸ì–´, ì‚¬ìš©ìê°€ í¸ì•ˆí•˜ê²Œ ìì‹ ì˜ ìƒê°ì„ ì´ì•¼ê¸°í•˜ë„ë¡ ë•ëŠ” ê²ƒì…ë‹ˆë‹¤.
    ë˜í•œ ì‚¬ìš©ìì˜ ì‘ë‹µì´ ë¶€ì¡±í•˜ë©´ ì¶”ê°€ ì§ˆë¬¸ì„ í•˜ì—¬ ì‚¬ìš©ìì˜ ì‘ë‹µì„ ìœ ë„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

    [ì§€ì‹œ]
    [í•µì‹¬ ì§ˆë¬¸ ëª©ë¡]ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì†Œê°œí•˜ë©´ì„œ, ì‚¬ìš©ìê°€ ë‹µë³€ì„ ì…ë ¥í•˜ë„ë¡ ìœ ë„í•˜ëŠ” í™˜ì˜ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤. 
    ì´ ë©”ì‹œì§€ëŠ” ì‚¬ìš©ìê°€ ë³´ê²Œ ë  ì²«ì¸ìƒì´ë¯€ë¡œ, í˜‘ë ¥ì ì¸ ë¶„ìœ„ê¸°ë¥¼ ì¡°ì„±í•˜ëŠ” ê²ƒì´ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.
    ëŒ€í™” ì´ë ¥ì— ë”°ë¼ ì¶”ê°€ ì§ˆë¬¸ì„ í•˜ì—¬ ì‚¬ìš©ìì˜ ì‘ë‹µì„ ìœ ë„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

    [ì¶œë ¥ í˜•ì‹]
    - ë‹¤ë¥¸ ì„¤ëª… ì—†ì´, ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ìµœì¢… í™˜ì˜ ë©”ì‹œì§€ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.

    [ê·œì¹™]
    - ì™œ ì´ ì§ˆë¬¸ë“¤ì´ í•„ìš”í•œì§€ ê°„ëµíˆ ì„¤ëª…í•˜ì—¬ ì‚¬ìš©ìë¥¼ ì•ˆì‹¬ì‹œí‚¤ì‹­ì‹œì˜¤. (ì˜ˆ: "ë” ì •í™•í•œ ê¸°ëŠ¥ ëª…ì„¸ì„œë¥¼ ë§Œë“¤ê¸° ìœ„í•´...")
    - ë”±ë”±í•œ ì§ˆë¬¸ ì–´ì¡°ê°€ ì•„ë‹Œ, ë¶€ë“œëŸ½ê³  ëŒ€í™”í•˜ëŠ” ë“¯í•œ ë¬¸ì²´ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
    - ë©”ì‹œì§€ ë§ˆì§€ë§‰ì—ëŠ” ì‚¬ìš©ìì˜ ë‹µë³€ì„ ê¸°ë‹¤ë¦°ë‹¤ëŠ” ë‰˜ì•™ìŠ¤ë¥¼ í’ê²¨ ëŒ€í™”ë¥¼ ìœ ë„í•˜ì‹­ì‹œì˜¤.
    - ì‚¬ìš©ìì˜ ì‘ë‹µì´ ë¶€ì¡±í•˜ë©´ is_completeë¥¼ falseë¡œ ì„¤ì •í•˜ê³  ask_questionì„ ì¶”ê°€ ì§ˆë¬¸ìœ¼ë¡œ ì„¤ì •í•˜ì‹­ì‹œì˜¤.
    - ì‚¬ìš©ìì˜ ì‘ë‹µì´ ì¶©ë¶„í•˜ë©´ is_completeë¥¼ trueë¡œ ì„¤ì •í•˜ê³  resultì— ì‚¬ìš©ìì˜ ì‘ë‹µ ê²°ê³¼ë¥¼ ì •ë¦¬í•œ í…ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
    - í•µì‹¬ ì§ˆë¬¸ì˜ ë‚´ìš©ì„ ë°˜ë“œì‹œ ì‚¬ìš©í•˜ë˜ ì§ˆë¬¸ì˜ í•µì‹¬ ë‚´ìš©ì„ ì§€í‚¤ë©´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì†Œê°œí•˜ì‹­ì‹œì˜¤, ì§ˆë¬¸ì˜ í•µì‹¬ì´ ë°”ë€Œì§€ ì•ŠëŠ”í•œ ìˆ˜ì •í•´ë„ ëœë‹¤.
    
    [ì‚°ì¶œë¬¼ ê¸°ì¤€]
    - ëª¨ë“  ì¶œë ¥ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤.
    - ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ ì œê³µëœ JSON ìŠ¤í‚¤ë§ˆ ì§€ì¹¨ì„ ì—„ê²©íˆ ë”°ë¥¸ë‹¤. í•„ë“œ ì´ë¦„ì„ ì„ì˜ë¡œ ë³€ê²½í•˜ì§€ ì•ŠëŠ”ë‹¤.
      - ask_question: ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ë©”ì‹œì§€ í…ìŠ¤íŠ¸.
      - is_complete: ì‚¬ìš©ìì˜ ì‘ë‹µì´ ì¶©ë¶„í•œì§€ íŒë‹¨í•˜ë¼. ì¶©ë¶„í•˜ë©´ true, ì•„ë‹ˆë©´ false.
      - result: ì§ˆë¬¸ì— ëŒ€í•œ ì‚¬ìš©ì ì‘ë‹µ ê²°ê³¼ë¥¼ ì •ë¦¬í•œ í…ìŠ¤íŠ¸.

    !!!ì¶œë ¥ í˜•ì‹ì´ ë‹¤ë¥´ë©´ ì—ëŸ¬ê°€ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë°˜ë“œì‹œ ë‹¤ìŒì˜ JSON ìŠ¤í‚¤ë§ˆ ì§€ì¹¨ì„ ì—„ê²©íˆ ë”°ë¼ì•¼ í•œë‹¤.!!!
    {format_instructions}
    """
    prompt = ChatPromptTemplate([
        ("system", system_prompt),
        MessagesPlaceholder(variable_name="messages"),
        ("human", "í•µì‹¬ ì§ˆë¬¸ ëª©ë¡: {clarifying_questions}")
    ])

    chain = prompt | llm | parser

    result = chain.invoke({
        "format_instructions": parser.get_format_instructions(),
        "clarifying_questions": state["clarifying_questions"],
        "messages": state["messages"]
    })

    updated_messages = state["messages"] + [AIMessage(content=result["ask_question"])]
    return {"ask_question": result["ask_question"], "result": result.get("result", ""), "is_complete": result.get("is_complete", False), "messages": updated_messages}

def user_response(state: AgentState):
    """ì‚¬ìš©ìì˜ ì‘ë‹µì„ ë°›ëŠ” ë…¸ë“œ"""
    print("--- ğŸ“ ì‚¬ìš©ìì˜ ì‘ë‹µì„ ë°›ëŠ” ì¤‘... ---")
    print(state.get("ask_question", "ì§ˆë¬¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìš”êµ¬ì‚¬í•­ì„ ì„¤ëª…í•´ ì£¼ì„¸ìš”."))
    response = input("ë‹µë³€: ")
    updated_messages = state["messages"] + [HumanMessage(content=response)]
    return {"messages": updated_messages, "request": response}

def is_complete(state: AgentState):
    return state["is_complete"] == True

def main(first_request: str):
    load_dotenv()

    workflow = StateGraph(AgentState)

    workflow.add_node("generate_clarifying_questions", generate_clarifying_questions)
    workflow.add_node("generate_user_request", generate_user_request)
    workflow.add_node("user_response", user_response)

    workflow.add_edge(START, "generate_clarifying_questions")
    workflow.add_edge("generate_clarifying_questions", "generate_user_request")
    workflow.add_conditional_edges("generate_user_request", is_complete, {True: END, False: "user_response"})
    workflow.add_edge("user_response", "generate_user_request")

    app = workflow.compile()

    initial_state = {
        "request": first_request,
        "clarifying_questions": [],
        "messages": [HumanMessage(content=first_request)],
        "is_complete": False,
        "ask_question": "",
        "result": ""
    }

    final_state = app.invoke(initial_state)
    print("--------------------------------")
    print(final_state["result"])
    print("--------------------------------")

    return final_state

if __name__ == "__main__":
    first_request = input()
    main(first_request)